{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b761f2-49a3-4873-b29b-5bb133afa5f8",
   "metadata": {},
   "source": [
    "# PyTorch的交叉熵、信息熵、二分类交叉熵、负对数似然、KL散度、余弦相似度的原理与代码讲解\n",
    "\n",
    "来自b站up主deep_thoughts 合集【PyTorch源码教程与前沿人工智能算法复现讲解】\n",
    "\n",
    "P_55_PyTorch的交叉熵、信息熵、二分类交叉熵、负对数似然、KL散度、余弦相似度的原理与代码讲解：\n",
    "\n",
    "https://www.bilibili.com/video/BV1Sv4y1A7dz/?spm_id_from=333.788&vd_source=18e91d849da09d846f771c89a366ed40\n",
    "\n",
    "损失函数官方文档：https://pytorch.org/docs/stable/nn.html#distance-functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9272296-cf44-4816-9340-b8b5ab17db5d",
   "metadata": {},
   "source": [
    "## 1. 交叉熵损失 Cross Entropy Loss (CE loss)\n",
    "\n",
    "官方文档：https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22c48009-5e21-4010-a780-72c3b5e016c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross entropy loss1: 2.4557747840881348\n",
      "cross entropy loss2: 2.339287519454956\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# logits shape: [BS, NC]\n",
    "batchsize = 2\n",
    "num_class = 4\n",
    "\n",
    "logits = torch.randn(batchsize, num_class)\n",
    "target_indices = torch.randint(num_class, size=(batchsize,))  # delta 目标分布\n",
    "target_logits = torch.randn(batchsize, num_class)  # 非 delta 目标分布\n",
    "\n",
    "## 1. 调用 Cross Entropy loss\n",
    "\n",
    "### method 1 for CE loss\n",
    "ce_loss_fun = torch.nn.CrossEntropyLoss()\n",
    "ce_loss = ce_loss_fun(logits, target_indices)\n",
    "print(f\"cross entropy loss1: {ce_loss}\")\n",
    "\n",
    "### method 2 for CE loss\n",
    "ce_loss = ce_loss_fun(logits, torch.softmax(target_logits, -1))\n",
    "print(f\"cross entropy loss2: {ce_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ca0af1-f00c-42c6-bcbc-95dfd3d43b01",
   "metadata": {},
   "source": [
    "## 2.负对数似然损失 Negative Log Likelihood Loss (NLL loss)\n",
    "\n",
    "官方文档：https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d1d86ff-1b86-442b-a64e-cdc75a0f4dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative log-likelihood loss: 2.4557747840881348\n"
     ]
    }
   ],
   "source": [
    "nll_fn = torch.nn.NLLLoss()\n",
    "nll_loss = nll_fn(torch.log(torch.softmax(logits, dim=-1)), target_indices)  # 与 CE loss结果相同\n",
    "print(f\"negative log-likelihood loss: {nll_loss}\")\n",
    "### cross entropy value = NLL value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14530ea4-4979-454f-9072-41d608d8130b",
   "metadata": {},
   "source": [
    "## 3. 调用 Kullback-Leibler divergence loss（KL loss）\n",
    "\n",
    "官方文档：https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html#torch.nn.KLDivLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f543925-0ab6-4dc6-a88b-70aa32082406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kullback-Leibler divergence loss:0.3004379868507385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\swin\\lib\\site-packages\\torch\\nn\\functional.py:2887: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
     ]
    }
   ],
   "source": [
    "kld_loss_fn = torch.nn.KLDivLoss()\n",
    "kld_loss = kld_loss_fn(torch.log(torch.softmax(logits, dim=-1)), torch.softmax(target_logits, dim=-1))\n",
    "print(f'Kullback-Leibler divergence loss:{kld_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582f52b8-5491-4425-bdc7-e411af89a4f4",
   "metadata": {},
   "source": [
    "## 4.验证 CE = IE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99583872-94fc-4e63-b29e-9102de95473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross entropy loss sample: tensor([1.9413, 2.7372])\n",
      "Kullback-Leibler divergence loss sample:tensor([0.6749, 1.7286])\n",
      "information entropy sample:tensor([1.2665, 1.0086])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "ce_loss_fn_sample = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "ce_loss_sample = ce_loss_fn_sample(logits, torch.softmax(target_logits, dim=-1))\n",
    "print(f\"cross entropy loss sample: {ce_loss_sample}\")\n",
    "\n",
    "kld_loss_fn_sample = torch.nn.KLDivLoss(reduction=\"none\")\n",
    "kld_loss_sample = kld_loss_fn_sample(torch.log(torch.softmax(logits, dim=-1)), torch.softmax(target_logits, dim=-1)).sum(-1)\n",
    "print(f'Kullback-Leibler divergence loss sample:{kld_loss_sample}')\n",
    "\n",
    "target_information_entropy = torch.distributions.Categorical(probs=torch.softmax(target_logits, dim=-1)).entropy()\n",
    "print(f'information entropy sample:{target_information_entropy}')  # IE为常数，如果目标分布是delta分布，IE=0\n",
    "\n",
    "print(torch.allclose(ce_loss_sample, kld_loss_sample+target_information_entropy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a588a6-a4de-468b-a199-6b9356636073",
   "metadata": {},
   "source": [
    "## 5.Binary Cross Entropy loss（BCE loss）\n",
    "\n",
    "官方文档：https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9e2ca7d-bdb4-4c63-a97f-3b60d25c5756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binart cross entropy loss: 0.6156336665153503\n",
      "negative likelihood loss binary: 0.6156336665153503\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "bce_loss_fn = torch.nn.BCELoss()\n",
    "logits = torch.randn(batchsize)\n",
    "prob_1 = torch.sigmoid(logits)\n",
    "target = torch.randint(2, size=(batchsize, ))\n",
    "bce_loss = bce_loss_fn(prob_1, target.float())\n",
    "print(f\"binart cross entropy loss: {bce_loss}\")\n",
    "\n",
    "### 用NLL loss代替BCE loss做二分类\n",
    "prob_0 = 1-prob_1.unsqueeze(-1)\n",
    "prob = torch.cat([prob_0, prob_1.unsqueeze(-1)], dim=-1)\n",
    "nll_loss_binary = nll_fn(torch.log(prob), target)\n",
    "print(f\"negative likelihood loss binary: {nll_loss_binary}\")\n",
    "print(torch.allclose(bce_loss, nll_loss_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8621b7d2-2288-48d9-9236-7f57d5b183e9",
   "metadata": {},
   "source": [
    "## 6.调用 Cosine Similarity loss\n",
    "\n",
    "官方文档：https://pytorch.org/docs/stable/generated/torch.nn.CosineEmbeddingLoss.html#torch.nn.CosineEmbeddingLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ad51ffa-20b5-4c30-80e8-d2a742d5b61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity loss: 0.01581306755542755\n"
     ]
    }
   ],
   "source": [
    "cosine_loss_fn = torch.nn.CosineEmbeddingLoss()\n",
    "v1 = torch.randn(batchsize, 512)\n",
    "v2 = torch.randn(batchsize, 512)\n",
    "target = torch.randint(2, size=(batchsize, ))*2-1\n",
    "cosine_loss = cosine_loss_fn(v1, v2, target)\n",
    "print(f\"cosine similarity loss: {cosine_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b53929-65be-43fd-adc6-8e7ca64ffccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
