{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ce56cc-3873-47b1-9257-0a0cc9a7f28b",
   "metadata": {},
   "source": [
    "# 基于PyTorch的文本分类项目模型与训练代码讲解\n",
    "\n",
    "来自b站up主deep_thoughts 合集【PyTorch源码教程与前沿人工智能算法复现讲解】\n",
    "\n",
    "P_32_基于PyTorch的文本分类项目模型与训练代码讲解：\n",
    "\n",
    "https://www.bilibili.com/video/BV1eD4y1F7o4/?spm_id_from=pageDriver&vd_source=18e91d849da09d846f771c89a366ed40\n",
    "\n",
    "***数据集***\n",
    "\n",
    "IMDB Dataset of 50K Movie Reviews:\n",
    "\n",
    "https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47f372ea-425c-427e-906d-f27e8e4ce564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "from torchtext.datasets import IMDB\n",
    "# conda install -c pytorch torchtext==${PyTorch所对应的版本} torchdata\n",
    "from torchtext.datasets.imdb import NUM_LINES\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.WARN,\n",
    "    stream=sys.stdout,\n",
    "    format=\"%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc4d2d9-b1d0-4b92-8aa4-d4b62c97aec7",
   "metadata": {},
   "source": [
    "# step1: 编写GCNN模型代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a4cc4c8-5409-4a28-a955-6477451ea9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 15000\n",
    "\n",
    "class GCNN(nn.Module):\n",
    "    def __init__(self, vocab_size=VOCAB_SIZE, embedding_dim=64, num_class=2):\n",
    "        super(GCNN, self).__init__()\n",
    "        \n",
    "        self.embedding_table = nn.Embedding(vocab_size, embedding_dim)\n",
    "        nn.init.xavier_uniform_(self.embedding_table.weight)\n",
    "        \n",
    "        self.conv_A_1 = nn.Conv1d(embedding_dim, 64, 15, stride=7)\n",
    "        self.conv_B_1 = nn.Conv1d(embedding_dim, 64, 15, stride=7)\n",
    "        \n",
    "        self.conv_A_2 = nn.Conv1d(64, 64, 15, stride=7)\n",
    "        self.conv_B_2 = nn.Conv1d(64, 64, 15, stride=7)\n",
    "        \n",
    "        self.output_linear1 = nn.Linear(64, 128)\n",
    "        self.output_linear2 = nn.Linear(128, num_class)\n",
    "        \n",
    "    def forward(self, word_index):\n",
    "        # 定义GCN网络的算子操作流程，基于句子单词ID输入得到分类logitsshuchu\n",
    "        \n",
    "        # 1. 通过word_index得到word_embedding\n",
    "        # word_index shape:[bs, max_seq_len, vocab_size]\n",
    "        word_embedding = self.embedding_table(word_index)  # [bs, max_seq_len, embedding_dim]\n",
    "        \n",
    "        # 2. 编写第一层 1D 门卷积模块\n",
    "        word_embedding = word_embedding.transpose(1,2)  # [bs, embedding_dim, max_seq_len]\n",
    "        A = self.conv_A_1(word_embedding)\n",
    "        B = self.conv_B_1(word_embedding)\n",
    "        H = A * torch.sigmoid(B)  # [bs, 64, max_seq_len]\n",
    "        \n",
    "        A = self.conv_A_2(H)\n",
    "        B = self.conv_B_2(H)\n",
    "        H = A * torch.sigmoid(B)  # [bs, 64, max_seq_len]\n",
    "        \n",
    "        # 3. 池化并经过全连接层\n",
    "        pool_output = torch.mean(H, dim=-1)  # 平均池化，得到[bs, 64]\n",
    "        linear1_output = self.output_linear1(pool_output)\n",
    "        logits = self.output_linear2(linear1_output) # [bs, 2]\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "class TextClassificationModel(nn.Module):\n",
    "    \"\"\" 简单版 embedding+DNN 模型 \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size=VOCAB_SIZE, embed_dim=64, num_class=2):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        \n",
    "    def forward(self, token_index):\n",
    "        embedded = self.embedding(token_index)  # shape: [bs, embedding_dim]\n",
    "        return self.fc(embedded)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd36650b-047d-45bc-be6d-0b28f03995f3",
   "metadata": {},
   "source": [
    "# step2 构建 IMDB DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25703a0a-a56c-40f4-99c1-c3314ca22553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\swin\\lib\\site-packages\\torch\\utils\\data\\datapipes\\utils\\common.py:25: UserWarning: Lambda function is not supported for pickle, please use regular python function or functools.partial instead.\n",
      "  \"Lambda function is not supported for pickle, please use \"\n",
      "D:\\anaconda3\\envs\\swin\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\selecting.py:54: UserWarning: Lambda function is not supported for pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\"Lambda function is not supported for pickle, please use \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "单词表大小：13351\n"
     ]
    }
   ],
   "source": [
    "# step2 构建 IMDB DataLoader\n",
    "\n",
    "BATCH_SIZE = 64 \n",
    "\n",
    "def yield_tokens(train_data_iter, tokenizer):\n",
    "    for i, sample in enumerate(train_data_iter):\n",
    "        label, comment = sample\n",
    "        yield tokenizer(comment)\n",
    "        \n",
    "train_data_iter = IMDB(root='.data', split='train')  # Dataset类型的对象\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_data_iter, tokenizer), min_freq=20, specials=[\"<unk>\"])\n",
    "vocab.set_default_index(0)\n",
    "print(f\"单词表大小：{len(vocab)}\")\n",
    "\n",
    "# 对 dataloader 生成的 minibatch 做后处理。将文本转化为张量\n",
    "def collate_fn(batch):\n",
    "    target = []\n",
    "    token_index = []\n",
    "    max_length = 0\n",
    "    for i, (label, comment) in enumerate(batch):\n",
    "        tokens = tokenizer(comment)\n",
    "        \n",
    "        token_index.append(vocab(tokens))\n",
    "        if len(tokens) > max_length:\n",
    "            max_length = len(tokens)\n",
    "        \n",
    "        if label == \"pos\":\n",
    "            target.append(0)\n",
    "        else:\n",
    "            target.append(1)\n",
    "    \n",
    "    token_index = [index + [0]*(max_length-len(index)) for index in token_index]\n",
    "    return (torch.tensor(target).to(torch.int64), torch.tensor(token_index).to(torch.int32))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8026bd-38ff-4e5a-b04c-5b0750354fde",
   "metadata": {},
   "source": [
    "# step3 编写训练代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0279d62-5ed6-4811-ae6b-9d5f0b67e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data_loader, eval_data_loader, model, optimizer, num_epoch, log_step_interval, save_step_interval, eval_step_interval,\n",
    "          save_path, resume=\"\"):\n",
    "    \"\"\" 此处 data_loader 是 map-style dataset \"\"\"\n",
    "    start_epoch = 0\n",
    "    start_step = 0\n",
    "    if resume != \"\":\n",
    "        # 加载之前训过的模型的参数文件\n",
    "        logging.warning(f\"loading from {resume}\")\n",
    "        checkpoint = torch.load(resume)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        start_step = checkpoint['step']\n",
    "        \n",
    "    for epoch_index in range(start_epoch, num_epoch):\n",
    "        ema_loss = 0.  # 指数移动平均 loss\n",
    "        num_batches = len(train_data_loader)\n",
    "        \n",
    "        for batch_index, (target, token_index) in enumerate(train_data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            step = num_batches*(epoch_index) + batch_index + 1\n",
    "            logits = model(token_index)\n",
    "            bce_loss = F.binary_cross_entropy(torch.sigmoid(logits), F.one_hot(target, num_classes=2).to(torch.float32))\n",
    "            ema_loss = 0.9*ema_loss + 0.1*bce_loss\n",
    "            bce_loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 0.1)  # 梯度截断\n",
    "            optimizer.step()  # 梯度更新\n",
    "            \n",
    "            if step % log_step_interval == 0:\n",
    "                logging.warning(f\"epoch_index: {epoch_index}, batch_index: {batch_index}, ema_loss: {ema_loss}\")\n",
    "                \n",
    "            if step % save_step_interval == 0:\n",
    "                os.makedirs(save_path, exist_ok=True)\n",
    "                save_file = os.path.join(save_path, f\"step_{step}.pt\")\n",
    "                torch.save({\n",
    "                    'epoch': epoch_index,\n",
    "                    'step': step,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': bce_loss,\n",
    "                }, save_file)\n",
    "                logging.warning(f\"checkpoint has been saved in {save_file}\")\n",
    "                \n",
    "            if step % eval_step_interval == 0:\n",
    "                logging.warning(\"start to do evaluation...\")\n",
    "                model.eval()\n",
    "                ema_eval_loss = 0\n",
    "                total_acc_account = 0\n",
    "                total_account = 0\n",
    "                for eval_batch_index, (eval_target, eval_token_index) in enumerate(eval_data_loader):\n",
    "                    total_account += eval_target.shape[0]\n",
    "                    eval_logits = model(eval_token_index)\n",
    "                    total_acc_account += (torch.argmax(eval_logits, dim=-1) == eval_target).sum().item()\n",
    "                    eval_bce_loss = F.binary_cross_entropy(torch.sigmoid(eval_logits), F.one_hot(eval_target, num_classes=2).to(torch.float32))\n",
    "                    ema_eval_loss = 0.9*ema_eval_loss + 0.1*eval_bce_loss\n",
    "                    \n",
    "                logging.warning(f\"eval_ema_loss: {ema_eval_loss}, eval_acc: {total_acc_account/total_account}\")\n",
    "                model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003a4dd0-b9fc-46c6-8df8-eb554d80f002",
   "metadata": {},
   "source": [
    "# step4 测试代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d104acf-2bac-46a6-bfe9-56db1df0edf0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型总参数： 1214594\n",
      "2022-11-23 23:51:51,286 (364936207:30) WARNING: epoch_index: 0, batch_index: 19, ema_loss: 0.6079292297363281\n",
      "2022-11-23 23:51:53,348 (364936207:30) WARNING: epoch_index: 0, batch_index: 39, ema_loss: 0.6819902658462524\n",
      "2022-11-23 23:51:55,257 (364936207:30) WARNING: epoch_index: 0, batch_index: 59, ema_loss: 0.6360833048820496\n",
      "2022-11-23 23:51:57,317 (364936207:30) WARNING: epoch_index: 0, batch_index: 79, ema_loss: 0.5575909614562988\n",
      "2022-11-23 23:51:59,271 (364936207:30) WARNING: epoch_index: 0, batch_index: 99, ema_loss: 0.5020145773887634\n",
      "2022-11-23 23:52:01,302 (364936207:30) WARNING: epoch_index: 0, batch_index: 119, ema_loss: 0.551681637763977\n",
      "2022-11-23 23:52:03,391 (364936207:30) WARNING: epoch_index: 0, batch_index: 139, ema_loss: 0.4571375548839569\n",
      "2022-11-23 23:52:05,506 (364936207:30) WARNING: epoch_index: 0, batch_index: 159, ema_loss: 0.4281674325466156\n",
      "2022-11-23 23:52:07,470 (364936207:30) WARNING: epoch_index: 0, batch_index: 179, ema_loss: 0.46580708026885986\n",
      "2022-11-23 23:52:09,444 (364936207:30) WARNING: epoch_index: 0, batch_index: 199, ema_loss: 0.3957836329936981\n",
      "2022-11-23 23:52:11,336 (364936207:30) WARNING: epoch_index: 0, batch_index: 219, ema_loss: 0.38812440633773804\n",
      "2022-11-23 23:52:13,297 (364936207:30) WARNING: epoch_index: 0, batch_index: 239, ema_loss: 0.43928906321525574\n",
      "2022-11-23 23:52:15,260 (364936207:30) WARNING: epoch_index: 0, batch_index: 259, ema_loss: 0.3660382032394409\n",
      "2022-11-23 23:52:17,187 (364936207:30) WARNING: epoch_index: 0, batch_index: 279, ema_loss: 0.3604171872138977\n",
      "2022-11-23 23:52:19,047 (364936207:30) WARNING: epoch_index: 0, batch_index: 299, ema_loss: 0.36249980330467224\n",
      "2022-11-23 23:52:19,048 (364936207:45) WARNING: start to do evaluation...\n",
      "2022-11-23 23:52:34,546 (364936207:57) WARNING: eval_ema_loss: 0.7023375630378723, eval_acc: 0.85952\n",
      "2022-11-23 23:52:36,629 (364936207:30) WARNING: epoch_index: 0, batch_index: 319, ema_loss: 0.4152453541755676\n",
      "2022-11-23 23:52:38,832 (364936207:30) WARNING: epoch_index: 0, batch_index: 339, ema_loss: 0.3458048403263092\n",
      "2022-11-23 23:52:40,957 (364936207:30) WARNING: epoch_index: 0, batch_index: 359, ema_loss: 0.38578400015830994\n",
      "2022-11-23 23:52:43,009 (364936207:30) WARNING: epoch_index: 0, batch_index: 379, ema_loss: 0.41541787981987\n",
      "2022-11-23 23:52:44,875 (364936207:30) WARNING: epoch_index: 1, batch_index: 8, ema_loss: 0.18326997756958008\n",
      "2022-11-23 23:52:46,865 (364936207:30) WARNING: epoch_index: 1, batch_index: 28, ema_loss: 0.405758261680603\n",
      "2022-11-23 23:52:48,896 (364936207:30) WARNING: epoch_index: 1, batch_index: 48, ema_loss: 0.2913771867752075\n",
      "2022-11-23 23:52:50,876 (364936207:30) WARNING: epoch_index: 1, batch_index: 68, ema_loss: 0.32707086205482483\n",
      "2022-11-23 23:52:52,876 (364936207:30) WARNING: epoch_index: 1, batch_index: 88, ema_loss: 0.32368046045303345\n",
      "2022-11-23 23:52:54,905 (364936207:30) WARNING: epoch_index: 1, batch_index: 108, ema_loss: 0.26161858439445496\n",
      "2022-11-23 23:52:54,919 (364936207:42) WARNING: checkpoint has been saved in ./logs_imdb_text_classification\\step_500.pt\n",
      "2022-11-23 23:52:56,755 (364936207:30) WARNING: epoch_index: 1, batch_index: 128, ema_loss: 0.31417402625083923\n",
      "2022-11-23 23:52:58,697 (364936207:30) WARNING: epoch_index: 1, batch_index: 148, ema_loss: 0.3479945659637451\n",
      "2022-11-23 23:53:00,855 (364936207:30) WARNING: epoch_index: 1, batch_index: 168, ema_loss: 0.32586023211479187\n",
      "2022-11-23 23:53:02,978 (364936207:30) WARNING: epoch_index: 1, batch_index: 188, ema_loss: 0.2878718972206116\n",
      "2022-11-23 23:53:04,958 (364936207:30) WARNING: epoch_index: 1, batch_index: 208, ema_loss: 0.4500585198402405\n",
      "2022-11-23 23:53:04,958 (364936207:45) WARNING: start to do evaluation...\n",
      "2022-11-23 23:53:20,546 (364936207:57) WARNING: eval_ema_loss: 0.7267922759056091, eval_acc: 0.85108\n",
      "2022-11-23 23:53:22,630 (364936207:30) WARNING: epoch_index: 1, batch_index: 228, ema_loss: 0.37288129329681396\n",
      "2022-11-23 23:53:24,583 (364936207:30) WARNING: epoch_index: 1, batch_index: 248, ema_loss: 0.28822776675224304\n",
      "2022-11-23 23:53:26,501 (364936207:30) WARNING: epoch_index: 1, batch_index: 268, ema_loss: 0.41385015845298767\n",
      "2022-11-23 23:53:28,375 (364936207:30) WARNING: epoch_index: 1, batch_index: 288, ema_loss: 0.3198210597038269\n",
      "2022-11-23 23:53:30,240 (364936207:30) WARNING: epoch_index: 1, batch_index: 308, ema_loss: 0.2969115376472473\n",
      "2022-11-23 23:53:32,237 (364936207:30) WARNING: epoch_index: 1, batch_index: 328, ema_loss: 0.30143648386001587\n",
      "2022-11-23 23:53:34,139 (364936207:30) WARNING: epoch_index: 1, batch_index: 348, ema_loss: 0.27169278264045715\n",
      "2022-11-23 23:53:36,182 (364936207:30) WARNING: epoch_index: 1, batch_index: 368, ema_loss: 0.3247341215610504\n",
      "2022-11-23 23:53:38,252 (364936207:30) WARNING: epoch_index: 1, batch_index: 388, ema_loss: 0.31042176485061646\n",
      "2022-11-23 23:53:40,173 (364936207:30) WARNING: epoch_index: 2, batch_index: 17, ema_loss: 0.215699702501297\n",
      "2022-11-23 23:53:42,127 (364936207:30) WARNING: epoch_index: 2, batch_index: 37, ema_loss: 0.2648511528968811\n",
      "2022-11-23 23:53:44,155 (364936207:30) WARNING: epoch_index: 2, batch_index: 57, ema_loss: 0.3060230612754822\n",
      "2022-11-23 23:53:46,086 (364936207:30) WARNING: epoch_index: 2, batch_index: 77, ema_loss: 0.24233953654766083\n",
      "2022-11-23 23:53:48,062 (364936207:30) WARNING: epoch_index: 2, batch_index: 97, ema_loss: 0.25046905875205994\n",
      "2022-11-23 23:53:50,025 (364936207:30) WARNING: epoch_index: 2, batch_index: 117, ema_loss: 0.24403713643550873\n",
      "2022-11-23 23:53:50,026 (364936207:45) WARNING: start to do evaluation...\n",
      "2022-11-23 23:54:05,912 (364936207:57) WARNING: eval_ema_loss: 1.143736481666565, eval_acc: 0.83672\n",
      "2022-11-23 23:54:08,034 (364936207:30) WARNING: epoch_index: 2, batch_index: 137, ema_loss: 0.292011022567749\n",
      "2022-11-23 23:54:10,087 (364936207:30) WARNING: epoch_index: 2, batch_index: 157, ema_loss: 0.26412585377693176\n",
      "2022-11-23 23:54:12,094 (364936207:30) WARNING: epoch_index: 2, batch_index: 177, ema_loss: 0.2353910505771637\n",
      "2022-11-23 23:54:14,292 (364936207:30) WARNING: epoch_index: 2, batch_index: 197, ema_loss: 0.2787033021450043\n",
      "2022-11-23 23:54:16,323 (364936207:30) WARNING: epoch_index: 2, batch_index: 217, ema_loss: 0.25068312883377075\n",
      "2022-11-23 23:54:16,338 (364936207:42) WARNING: checkpoint has been saved in ./logs_imdb_text_classification\\step_1000.pt\n",
      "2022-11-23 23:54:18,277 (364936207:30) WARNING: epoch_index: 2, batch_index: 237, ema_loss: 0.2618252635002136\n",
      "2022-11-23 23:54:20,314 (364936207:30) WARNING: epoch_index: 2, batch_index: 257, ema_loss: 0.2569918930530548\n",
      "2022-11-23 23:54:22,254 (364936207:30) WARNING: epoch_index: 2, batch_index: 277, ema_loss: 0.2474147230386734\n",
      "2022-11-23 23:54:24,117 (364936207:30) WARNING: epoch_index: 2, batch_index: 297, ema_loss: 0.2415960282087326\n",
      "2022-11-23 23:54:26,221 (364936207:30) WARNING: epoch_index: 2, batch_index: 317, ema_loss: 0.22447653114795685\n",
      "2022-11-23 23:54:28,086 (364936207:30) WARNING: epoch_index: 2, batch_index: 337, ema_loss: 0.24782279133796692\n",
      "2022-11-23 23:54:30,138 (364936207:30) WARNING: epoch_index: 2, batch_index: 357, ema_loss: 0.28578218817710876\n",
      "2022-11-23 23:54:32,134 (364936207:30) WARNING: epoch_index: 2, batch_index: 377, ema_loss: 0.2783919870853424\n",
      "2022-11-23 23:54:34,074 (364936207:30) WARNING: epoch_index: 3, batch_index: 6, ema_loss: 0.11388067156076431\n",
      "2022-11-23 23:54:35,995 (364936207:30) WARNING: epoch_index: 3, batch_index: 26, ema_loss: 0.1542133241891861\n",
      "2022-11-23 23:54:35,995 (364936207:45) WARNING: start to do evaluation...\n",
      "2022-11-23 23:54:51,658 (364936207:57) WARNING: eval_ema_loss: 0.7433782815933228, eval_acc: 0.8668\n",
      "2022-11-23 23:54:53,585 (364936207:30) WARNING: epoch_index: 3, batch_index: 46, ema_loss: 0.20940180122852325\n",
      "2022-11-23 23:54:55,628 (364936207:30) WARNING: epoch_index: 3, batch_index: 66, ema_loss: 0.27076295018196106\n",
      "2022-11-23 23:54:57,515 (364936207:30) WARNING: epoch_index: 3, batch_index: 86, ema_loss: 0.22865350544452667\n",
      "2022-11-23 23:54:59,543 (364936207:30) WARNING: epoch_index: 3, batch_index: 106, ema_loss: 0.23255228996276855\n",
      "2022-11-23 23:55:01,566 (364936207:30) WARNING: epoch_index: 3, batch_index: 126, ema_loss: 0.26772433519363403\n",
      "2022-11-23 23:55:03,590 (364936207:30) WARNING: epoch_index: 3, batch_index: 146, ema_loss: 0.20133735239505768\n",
      "2022-11-23 23:55:05,678 (364936207:30) WARNING: epoch_index: 3, batch_index: 166, ema_loss: 0.18004392087459564\n",
      "2022-11-23 23:55:07,677 (364936207:30) WARNING: epoch_index: 3, batch_index: 186, ema_loss: 0.2657313942909241\n",
      "2022-11-23 23:55:09,841 (364936207:30) WARNING: epoch_index: 3, batch_index: 206, ema_loss: 0.20881515741348267\n",
      "2022-11-23 23:55:11,822 (364936207:30) WARNING: epoch_index: 3, batch_index: 226, ema_loss: 0.21553069353103638\n",
      "2022-11-23 23:55:13,727 (364936207:30) WARNING: epoch_index: 3, batch_index: 246, ema_loss: 0.1873081475496292\n",
      "2022-11-23 23:55:15,658 (364936207:30) WARNING: epoch_index: 3, batch_index: 266, ema_loss: 0.25443196296691895\n",
      "2022-11-23 23:55:17,801 (364936207:30) WARNING: epoch_index: 3, batch_index: 286, ema_loss: 0.2250232696533203\n",
      "2022-11-23 23:55:19,772 (364936207:30) WARNING: epoch_index: 3, batch_index: 306, ema_loss: 0.2278328239917755\n",
      "2022-11-23 23:55:22,177 (364936207:30) WARNING: epoch_index: 3, batch_index: 326, ema_loss: 0.2112034261226654\n",
      "2022-11-23 23:55:22,191 (364936207:42) WARNING: checkpoint has been saved in ./logs_imdb_text_classification\\step_1500.pt\n",
      "2022-11-23 23:55:22,191 (364936207:45) WARNING: start to do evaluation...\n",
      "2022-11-23 23:55:38,507 (364936207:57) WARNING: eval_ema_loss: 0.8888096213340759, eval_acc: 0.85896\n",
      "2022-11-23 23:55:40,544 (364936207:30) WARNING: epoch_index: 3, batch_index: 346, ema_loss: 0.20455032587051392\n",
      "2022-11-23 23:55:42,486 (364936207:30) WARNING: epoch_index: 3, batch_index: 366, ema_loss: 0.2398311346769333\n",
      "2022-11-23 23:55:44,452 (364936207:30) WARNING: epoch_index: 3, batch_index: 386, ema_loss: 0.17708633840084076\n",
      "2022-11-23 23:55:46,436 (364936207:30) WARNING: epoch_index: 4, batch_index: 15, ema_loss: 0.1524476259946823\n",
      "2022-11-23 23:55:48,491 (364936207:30) WARNING: epoch_index: 4, batch_index: 35, ema_loss: 0.13248883187770844\n",
      "2022-11-23 23:55:50,505 (364936207:30) WARNING: epoch_index: 4, batch_index: 55, ema_loss: 0.11114088445901871\n",
      "2022-11-23 23:55:52,626 (364936207:30) WARNING: epoch_index: 4, batch_index: 75, ema_loss: 0.16569899022579193\n",
      "2022-11-23 23:55:54,638 (364936207:30) WARNING: epoch_index: 4, batch_index: 95, ema_loss: 0.16633442044258118\n",
      "2022-11-23 23:55:56,499 (364936207:30) WARNING: epoch_index: 4, batch_index: 115, ema_loss: 0.1751587688922882\n",
      "2022-11-23 23:55:58,600 (364936207:30) WARNING: epoch_index: 4, batch_index: 135, ema_loss: 0.14156582951545715\n",
      "2022-11-23 23:56:00,663 (364936207:30) WARNING: epoch_index: 4, batch_index: 155, ema_loss: 0.18824641406536102\n",
      "2022-11-23 23:56:02,703 (364936207:30) WARNING: epoch_index: 4, batch_index: 175, ema_loss: 0.16832849383354187\n",
      "2022-11-23 23:56:04,816 (364936207:30) WARNING: epoch_index: 4, batch_index: 195, ema_loss: 0.18849816918373108\n",
      "2022-11-23 23:56:06,757 (364936207:30) WARNING: epoch_index: 4, batch_index: 215, ema_loss: 0.13919168710708618\n",
      "2022-11-23 23:56:08,720 (364936207:30) WARNING: epoch_index: 4, batch_index: 235, ema_loss: 0.1729550063610077\n",
      "2022-11-23 23:56:08,721 (364936207:45) WARNING: start to do evaluation...\n",
      "2022-11-23 23:56:24,117 (364936207:57) WARNING: eval_ema_loss: 0.503492534160614, eval_acc: 0.85296\n",
      "2022-11-23 23:56:26,035 (364936207:30) WARNING: epoch_index: 4, batch_index: 255, ema_loss: 0.2506423592567444\n",
      "2022-11-23 23:56:27,989 (364936207:30) WARNING: epoch_index: 4, batch_index: 275, ema_loss: 0.17582273483276367\n",
      "2022-11-23 23:56:30,037 (364936207:30) WARNING: epoch_index: 4, batch_index: 295, ema_loss: 0.14551064372062683\n",
      "2022-11-23 23:56:32,034 (364936207:30) WARNING: epoch_index: 4, batch_index: 315, ema_loss: 0.20136882364749908\n",
      "2022-11-23 23:56:33,966 (364936207:30) WARNING: epoch_index: 4, batch_index: 335, ema_loss: 0.18541064858436584\n",
      "2022-11-23 23:56:35,875 (364936207:30) WARNING: epoch_index: 4, batch_index: 355, ema_loss: 0.20082339644432068\n",
      "2022-11-23 23:56:37,769 (364936207:30) WARNING: epoch_index: 4, batch_index: 375, ema_loss: 0.15470218658447266\n",
      "2022-11-23 23:56:39,754 (364936207:30) WARNING: epoch_index: 5, batch_index: 4, ema_loss: 0.020466959103941917\n",
      "2022-11-23 23:56:42,071 (364936207:30) WARNING: epoch_index: 5, batch_index: 24, ema_loss: 0.11057081818580627\n",
      "2022-11-23 23:56:44,227 (364936207:30) WARNING: epoch_index: 5, batch_index: 44, ema_loss: 0.08044537901878357\n",
      "2022-11-23 23:56:44,241 (364936207:42) WARNING: checkpoint has been saved in ./logs_imdb_text_classification\\step_2000.pt\n",
      "2022-11-23 23:56:46,225 (364936207:30) WARNING: epoch_index: 5, batch_index: 64, ema_loss: 0.11477413773536682\n",
      "2022-11-23 23:56:48,157 (364936207:30) WARNING: epoch_index: 5, batch_index: 84, ema_loss: 0.10538765043020248\n",
      "2022-11-23 23:56:50,121 (364936207:30) WARNING: epoch_index: 5, batch_index: 104, ema_loss: 0.06430541723966599\n",
      "2022-11-23 23:56:52,659 (364936207:30) WARNING: epoch_index: 5, batch_index: 124, ema_loss: 0.11656993627548218\n",
      "2022-11-23 23:56:55,118 (364936207:30) WARNING: epoch_index: 5, batch_index: 144, ema_loss: 0.11786434054374695\n",
      "2022-11-23 23:56:55,119 (364936207:45) WARNING: start to do evaluation...\n",
      "2022-11-23 23:57:11,985 (364936207:57) WARNING: eval_ema_loss: 3.324460506439209, eval_acc: 0.83844\n",
      "2022-11-23 23:57:14,238 (364936207:30) WARNING: epoch_index: 5, batch_index: 164, ema_loss: 0.09805437922477722\n",
      "2022-11-23 23:57:16,522 (364936207:30) WARNING: epoch_index: 5, batch_index: 184, ema_loss: 0.09247585386037827\n",
      "2022-11-23 23:57:18,842 (364936207:30) WARNING: epoch_index: 5, batch_index: 204, ema_loss: 0.08010342717170715\n",
      "2022-11-23 23:57:21,061 (364936207:30) WARNING: epoch_index: 5, batch_index: 224, ema_loss: 0.06593007594347\n",
      "2022-11-23 23:57:23,349 (364936207:30) WARNING: epoch_index: 5, batch_index: 244, ema_loss: 0.09198112785816193\n",
      "2022-11-23 23:57:25,708 (364936207:30) WARNING: epoch_index: 5, batch_index: 264, ema_loss: 0.09582531452178955\n",
      "2022-11-23 23:57:27,907 (364936207:30) WARNING: epoch_index: 5, batch_index: 284, ema_loss: 0.06365650147199631\n",
      "2022-11-23 23:57:30,468 (364936207:30) WARNING: epoch_index: 5, batch_index: 304, ema_loss: 0.06946275383234024\n",
      "2022-11-23 23:57:32,596 (364936207:30) WARNING: epoch_index: 5, batch_index: 324, ema_loss: 0.08913972228765488\n",
      "2022-11-23 23:57:35,056 (364936207:30) WARNING: epoch_index: 5, batch_index: 344, ema_loss: 0.07242628931999207\n",
      "2022-11-23 23:57:38,093 (364936207:30) WARNING: epoch_index: 5, batch_index: 364, ema_loss: 0.08573421090841293\n",
      "2022-11-23 23:57:40,538 (364936207:30) WARNING: epoch_index: 5, batch_index: 384, ema_loss: 0.09277474135160446\n",
      "2022-11-23 23:57:42,880 (364936207:30) WARNING: epoch_index: 6, batch_index: 13, ema_loss: 0.020120708271861076\n",
      "2022-11-23 23:57:46,352 (364936207:30) WARNING: epoch_index: 6, batch_index: 33, ema_loss: 0.028591563925147057\n",
      "2022-11-23 23:57:50,595 (364936207:30) WARNING: epoch_index: 6, batch_index: 53, ema_loss: 0.024770818650722504\n",
      "2022-11-23 23:57:50,596 (364936207:45) WARNING: start to do evaluation...\n",
      "2022-11-23 23:58:05,065 (364936207:57) WARNING: eval_ema_loss: 3.1510798931121826, eval_acc: 0.86196\n",
      "2022-11-23 23:58:08,927 (364936207:30) WARNING: epoch_index: 6, batch_index: 73, ema_loss: 0.013493669219315052\n",
      "2022-11-23 23:58:13,059 (364936207:30) WARNING: epoch_index: 6, batch_index: 93, ema_loss: 0.0165933296084404\n",
      "2022-11-23 23:58:17,611 (364936207:30) WARNING: epoch_index: 6, batch_index: 113, ema_loss: 0.018562395125627518\n",
      "2022-11-23 23:58:22,658 (364936207:30) WARNING: epoch_index: 6, batch_index: 133, ema_loss: 0.01887887716293335\n",
      "2022-11-23 23:58:27,233 (364936207:30) WARNING: epoch_index: 6, batch_index: 153, ema_loss: 0.028714096173644066\n",
      "2022-11-23 23:58:27,246 (364936207:42) WARNING: checkpoint has been saved in ./logs_imdb_text_classification\\step_2500.pt\n",
      "2022-11-23 23:58:32,248 (364936207:30) WARNING: epoch_index: 6, batch_index: 173, ema_loss: 0.14392508566379547\n",
      "2022-11-23 23:58:36,661 (364936207:30) WARNING: epoch_index: 6, batch_index: 193, ema_loss: 0.03648797795176506\n",
      "2022-11-23 23:58:40,872 (364936207:30) WARNING: epoch_index: 6, batch_index: 213, ema_loss: 0.02650117501616478\n",
      "2022-11-23 23:58:45,586 (364936207:30) WARNING: epoch_index: 6, batch_index: 233, ema_loss: 0.11496177315711975\n",
      "2022-11-23 23:58:50,288 (364936207:30) WARNING: epoch_index: 6, batch_index: 253, ema_loss: 0.12608538568019867\n",
      "2022-11-23 23:58:53,987 (364936207:30) WARNING: epoch_index: 6, batch_index: 273, ema_loss: 0.05069161579012871\n",
      "2022-11-23 23:58:58,641 (364936207:30) WARNING: epoch_index: 6, batch_index: 293, ema_loss: 0.04700214043259621\n",
      "2022-11-23 23:59:03,291 (364936207:30) WARNING: epoch_index: 6, batch_index: 313, ema_loss: 0.028984611853957176\n",
      "2022-11-23 23:59:07,992 (364936207:30) WARNING: epoch_index: 6, batch_index: 333, ema_loss: 0.029740454629063606\n",
      "2022-11-23 23:59:12,810 (364936207:30) WARNING: epoch_index: 6, batch_index: 353, ema_loss: 0.06720317155122757\n",
      "2022-11-23 23:59:12,811 (364936207:45) WARNING: start to do evaluation...\n",
      "2022-11-23 23:59:27,159 (364936207:57) WARNING: eval_ema_loss: 3.4091360569000244, eval_acc: 0.85904\n",
      "2022-11-23 23:59:32,080 (364936207:30) WARNING: epoch_index: 6, batch_index: 373, ema_loss: 0.03522295504808426\n",
      "2022-11-23 23:59:36,750 (364936207:30) WARNING: epoch_index: 7, batch_index: 2, ema_loss: 0.003947772551327944\n",
      "2022-11-23 23:59:41,634 (364936207:30) WARNING: epoch_index: 7, batch_index: 22, ema_loss: 0.0070999483577907085\n",
      "2022-11-23 23:59:46,727 (364936207:30) WARNING: epoch_index: 7, batch_index: 42, ema_loss: 0.004655270837247372\n",
      "2022-11-23 23:59:52,355 (364936207:30) WARNING: epoch_index: 7, batch_index: 62, ema_loss: 0.015782058238983154\n",
      "2022-11-23 23:59:57,724 (364936207:30) WARNING: epoch_index: 7, batch_index: 82, ema_loss: 0.011440168134868145\n",
      "2022-11-24 00:00:03,642 (364936207:30) WARNING: epoch_index: 7, batch_index: 102, ema_loss: 0.030825790017843246\n",
      "2022-11-24 00:00:09,933 (364936207:30) WARNING: epoch_index: 7, batch_index: 122, ema_loss: 0.00932826567441225\n",
      "2022-11-24 00:00:16,384 (364936207:30) WARNING: epoch_index: 7, batch_index: 142, ema_loss: 0.004183018580079079\n",
      "2022-11-24 00:00:22,835 (364936207:30) WARNING: epoch_index: 7, batch_index: 162, ema_loss: 0.09596329927444458\n",
      "2022-11-24 00:00:29,291 (364936207:30) WARNING: epoch_index: 7, batch_index: 182, ema_loss: 0.02083260752260685\n",
      "2022-11-24 00:00:36,050 (364936207:30) WARNING: epoch_index: 7, batch_index: 202, ema_loss: 0.0029528408776968718\n",
      "2022-11-24 00:00:42,730 (364936207:30) WARNING: epoch_index: 7, batch_index: 222, ema_loss: 0.0012996848672628403\n",
      "2022-11-24 00:00:49,399 (364936207:30) WARNING: epoch_index: 7, batch_index: 242, ema_loss: 0.00046674636541865766\n",
      "2022-11-24 00:00:56,991 (364936207:30) WARNING: epoch_index: 7, batch_index: 262, ema_loss: 0.007385676726698875\n",
      "2022-11-24 00:00:57,005 (364936207:42) WARNING: checkpoint has been saved in ./logs_imdb_text_classification\\step_3000.pt\n",
      "2022-11-24 00:00:57,005 (364936207:45) WARNING: start to do evaluation...\n",
      "2022-11-24 00:01:11,419 (364936207:57) WARNING: eval_ema_loss: 8.358561515808105, eval_acc: 0.85508\n",
      "2022-11-24 00:01:17,937 (364936207:30) WARNING: epoch_index: 7, batch_index: 282, ema_loss: 0.006990877445787191\n",
      "2022-11-24 00:01:25,414 (364936207:30) WARNING: epoch_index: 7, batch_index: 302, ema_loss: 0.03354687988758087\n",
      "2022-11-24 00:01:31,497 (364936207:30) WARNING: epoch_index: 7, batch_index: 322, ema_loss: 0.017637714743614197\n",
      "2022-11-24 00:01:37,942 (364936207:30) WARNING: epoch_index: 7, batch_index: 342, ema_loss: 0.0026097798254340887\n",
      "2022-11-24 00:01:44,892 (364936207:30) WARNING: epoch_index: 7, batch_index: 362, ema_loss: 0.014246947132050991\n",
      "2022-11-24 00:01:51,999 (364936207:30) WARNING: epoch_index: 7, batch_index: 382, ema_loss: 0.005697227083146572\n",
      "2022-11-24 00:01:59,436 (364936207:30) WARNING: epoch_index: 8, batch_index: 11, ema_loss: 0.0029953315388411283\n",
      "2022-11-24 00:02:07,457 (364936207:30) WARNING: epoch_index: 8, batch_index: 31, ema_loss: 0.05283236503601074\n",
      "2022-11-24 00:02:13,845 (364936207:30) WARNING: epoch_index: 8, batch_index: 51, ema_loss: 0.006428447552025318\n",
      "2022-11-24 00:02:21,392 (364936207:30) WARNING: epoch_index: 8, batch_index: 71, ema_loss: 0.0008175516850315034\n",
      "2022-11-24 00:02:28,245 (364936207:30) WARNING: epoch_index: 8, batch_index: 91, ema_loss: 0.00012181518832221627\n",
      "2022-11-24 00:02:35,117 (364936207:30) WARNING: epoch_index: 8, batch_index: 111, ema_loss: 0.0019603120163083076\n",
      "2022-11-24 00:02:42,123 (364936207:30) WARNING: epoch_index: 8, batch_index: 131, ema_loss: 0.00030950759537518024\n",
      "2022-11-24 00:02:50,153 (364936207:30) WARNING: epoch_index: 8, batch_index: 151, ema_loss: 0.0005665653734467924\n",
      "2022-11-24 00:02:57,773 (364936207:30) WARNING: epoch_index: 8, batch_index: 171, ema_loss: 0.008736476302146912\n",
      "2022-11-24 00:02:57,773 (364936207:45) WARNING: start to do evaluation...\n",
      "2022-11-24 00:03:12,151 (364936207:57) WARNING: eval_ema_loss: 8.607288360595703, eval_acc: 0.85664\n",
      "2022-11-24 00:03:18,886 (364936207:30) WARNING: epoch_index: 8, batch_index: 191, ema_loss: 0.0017329780384898186\n",
      "2022-11-24 00:03:26,770 (364936207:30) WARNING: epoch_index: 8, batch_index: 211, ema_loss: 0.004314106423407793\n",
      "2022-11-24 00:03:34,470 (364936207:30) WARNING: epoch_index: 8, batch_index: 231, ema_loss: 0.00328609487041831\n",
      "2022-11-24 00:03:42,310 (364936207:30) WARNING: epoch_index: 8, batch_index: 251, ema_loss: 0.01281867828220129\n",
      "2022-11-24 00:03:48,652 (364936207:30) WARNING: epoch_index: 8, batch_index: 271, ema_loss: 0.0015600606566295028\n",
      "2022-11-24 00:03:56,037 (364936207:30) WARNING: epoch_index: 8, batch_index: 291, ema_loss: 0.00023972286726348102\n",
      "2022-11-24 00:04:03,601 (364936207:30) WARNING: epoch_index: 8, batch_index: 311, ema_loss: 0.00037582102231681347\n",
      "2022-11-24 00:04:11,271 (364936207:30) WARNING: epoch_index: 8, batch_index: 331, ema_loss: 4.707390326075256e-05\n",
      "2022-11-24 00:04:18,345 (364936207:30) WARNING: epoch_index: 8, batch_index: 351, ema_loss: 0.0003695813938975334\n",
      "2022-11-24 00:04:24,782 (364936207:30) WARNING: epoch_index: 8, batch_index: 371, ema_loss: 0.004290786571800709\n",
      "2022-11-24 00:04:24,795 (364936207:42) WARNING: checkpoint has been saved in ./logs_imdb_text_classification\\step_3500.pt\n",
      "2022-11-24 00:04:31,745 (364936207:30) WARNING: epoch_index: 9, batch_index: 0, ema_loss: 3.5250959484756095e-08\n",
      "2022-11-24 00:04:38,546 (364936207:30) WARNING: epoch_index: 9, batch_index: 20, ema_loss: 0.00026966939913108945\n",
      "2022-11-24 00:04:45,740 (364936207:30) WARNING: epoch_index: 9, batch_index: 40, ema_loss: 3.800819831667468e-05\n",
      "2022-11-24 00:04:52,804 (364936207:30) WARNING: epoch_index: 9, batch_index: 60, ema_loss: 0.00021333429322112352\n",
      "2022-11-24 00:05:00,092 (364936207:30) WARNING: epoch_index: 9, batch_index: 80, ema_loss: 0.025884002447128296\n",
      "2022-11-24 00:05:00,092 (364936207:45) WARNING: start to do evaluation...\n",
      "2022-11-24 00:05:14,582 (364936207:57) WARNING: eval_ema_loss: 7.756167411804199, eval_acc: 0.85692\n",
      "2022-11-24 00:05:21,181 (364936207:30) WARNING: epoch_index: 9, batch_index: 100, ema_loss: 0.0033285662066191435\n",
      "2022-11-24 00:05:28,236 (364936207:30) WARNING: epoch_index: 9, batch_index: 120, ema_loss: 0.0007910957792773843\n",
      "2022-11-24 00:05:34,887 (364936207:30) WARNING: epoch_index: 9, batch_index: 140, ema_loss: 0.02349265106022358\n",
      "2022-11-24 00:05:41,789 (364936207:30) WARNING: epoch_index: 9, batch_index: 160, ema_loss: 0.035527247935533524\n",
      "2022-11-24 00:05:48,798 (364936207:30) WARNING: epoch_index: 9, batch_index: 180, ema_loss: 0.04548781365156174\n",
      "2022-11-24 00:05:55,969 (364936207:30) WARNING: epoch_index: 9, batch_index: 200, ema_loss: 0.028902070596814156\n",
      "2022-11-24 00:06:03,281 (364936207:30) WARNING: epoch_index: 9, batch_index: 220, ema_loss: 0.003524423809722066\n",
      "2022-11-24 00:06:09,999 (364936207:30) WARNING: epoch_index: 9, batch_index: 240, ema_loss: 0.000587772112339735\n",
      "2022-11-24 00:06:17,650 (364936207:30) WARNING: epoch_index: 9, batch_index: 260, ema_loss: 0.0034496576990932226\n",
      "2022-11-24 00:06:24,635 (364936207:30) WARNING: epoch_index: 9, batch_index: 280, ema_loss: 0.0004561429377645254\n",
      "2022-11-24 00:06:32,132 (364936207:30) WARNING: epoch_index: 9, batch_index: 300, ema_loss: 0.0019164332188665867\n",
      "2022-11-24 00:06:38,345 (364936207:30) WARNING: epoch_index: 9, batch_index: 320, ema_loss: 0.00027748162392526865\n",
      "2022-11-24 00:06:45,106 (364936207:30) WARNING: epoch_index: 9, batch_index: 340, ema_loss: 0.005784931592643261\n",
      "2022-11-24 00:06:52,331 (364936207:30) WARNING: epoch_index: 9, batch_index: 360, ema_loss: 0.0009840853745117784\n",
      "2022-11-24 00:06:58,318 (364936207:30) WARNING: epoch_index: 9, batch_index: 380, ema_loss: 0.0007628095918335021\n",
      "2022-11-24 00:06:58,319 (364936207:45) WARNING: start to do evaluation...\n",
      "2022-11-24 00:07:12,650 (364936207:57) WARNING: eval_ema_loss: 6.801450729370117, eval_acc: 0.85848\n"
     ]
    }
   ],
   "source": [
    "model = GCNN()\n",
    "# model = TextClassificationModel()\n",
    "print(\"模型总参数：\", sum(p.numel() for p in model.parameters()))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_data_iter = IMDB(root='.data', split='train')  # Dataset 类型的对象\n",
    "train_data_loader = torch.utils.data.DataLoader(to_map_style_dataset(train_data_iter), batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)\n",
    "\n",
    "eval_data_iter = IMDB(root='.data', split='test')  # Dataset 类型的对象\n",
    "eval_data_loader = torch.utils.data.DataLoader(to_map_style_dataset(eval_data_iter), batch_size=8, collate_fn=collate_fn)\n",
    "\n",
    "train(train_data_loader, eval_data_loader, model, optimizer, num_epoch=10, log_step_interval=20, save_step_interval=500, eval_step_interval=300,\n",
    "          save_path=\"./logs_imdb_text_classification\", resume=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95640ad-1489-424b-9cdc-1ac55baba117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
