{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81794a4f-842a-49af-b1d3-5683b590cc0f",
   "metadata": {},
   "source": [
    "# PyTorch GRU的原理及其手写复现\n",
    "\n",
    "来自b站up主deep_thoughts 合集【PyTorch源码教程与前沿人工智能算法复现讲解】\n",
    "\n",
    "P_31_PyTorch_GRU的原理及其手写复现：\n",
    "\n",
    "https://www.bilibili.com/video/BV1jm4y1Q7uh/?spm_id_from=pageDriver&vd_source=18e91d849da09d846f771c89a366ed40\n",
    "\n",
    "***资料***\n",
    "\n",
    "PyTorch GRU 官方文档：\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.GRU.html#torch.nn.GRU\n",
    "\n",
    "***论文***\n",
    "\n",
    "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling：\n",
    "\n",
    "https://arxiv.org/pdf/1412.3555.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc88151c-c46d-49e0-ad05-2109d375439f",
   "metadata": {},
   "source": [
    "## GRU 公式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12606f23-dab9-4dd7-8447-4cc84e43203f",
   "metadata": {},
   "source": [
    "$r_t = \\sigma(W_{ir}x_t + b_{ir} + W_{hr}h_{(t-1)}+b_{hr})$\n",
    "\n",
    "$z_t = \\sigma(W_{iz}x_t + b_{iz} + W_{hz}h_{(t-1)}+b_{hz})$\n",
    "\n",
    "$n_t = tanh(W_{in}x_t + b_{in} + r_t * (W_{hn} h_{(t-1)} + b_{hn}))$\n",
    "\n",
    "$h_t = (1-z_t)*n_t + z_t*h_(t-1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841008fa-90e9-4120-9c26-016304839d1e",
   "metadata": {},
   "source": [
    "## 查看 LSTM 和 GRU 的参数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d10664a3-c89b-400c-93c4-fc50c200b1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "lstm_layer = nn.LSTM(3, 5)\n",
    "gru_layer = nn.GRU(3, 5)\n",
    "print(sum(p.numel() for p in lstm_layer.parameters()))\n",
    "print(sum(p.numel() for p in gru_layer.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27d05bf-4343-4884-8e48-b244037bbd0e",
   "metadata": {},
   "source": [
    "## 逐行实现GRU网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e84709c-af14-4bcc-8793-08937150edd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1634, -0.4756, -0.7797,  0.3584, -0.2965],\n",
      "         [ 0.0975, -0.2879, -0.7104,  0.1393, -0.3203],\n",
      "         [ 0.1759, -0.2848, -0.3293,  0.0650, -0.3861]],\n",
      "\n",
      "        [[-0.3849,  0.3312,  0.6562,  1.2750, -0.6056],\n",
      "         [-0.4849, -0.0553,  0.5266,  0.9541, -0.7548],\n",
      "         [-0.0237, -0.0220,  0.4013,  0.7372, -0.7686]]],\n",
      "       grad_fn=<TransposeBackward1>)\n",
      "weight_ih_l0 torch.Size([15, 4])\n",
      "weight_hh_l0 torch.Size([15, 5])\n",
      "bias_ih_l0 torch.Size([15])\n",
      "bias_hh_l0 torch.Size([15])\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def gru_forward(input, initial_states, w_ih, w_hh, b_ih, b_hh):\n",
    "    prev_h = initial_states\n",
    "    bs, T, i_size = input.shape\n",
    "    h_size = w_ih.shape[0] // 3\n",
    "    \n",
    "    # 对权重扩维， 复制成 batch_size 倍\n",
    "    batch_w_ih = w_ih.unsqueeze(0).tile(bs, 1, 1)\n",
    "    batch_w_hh = w_hh.unsqueeze(0).tile(bs, 1, 1)\n",
    "    \n",
    "    output = torch.zeros(bs, T, h_size)  # GRU网络的输出状态序列\n",
    "    \n",
    "    for t in range(T):\n",
    "        x = input[:, t, :]  # t 时刻 GRU cell 的输入特征向量, [bs, i_size]\n",
    "        w_times_x = torch.bmm(batch_w_ih, x.unsqueeze(-1))  # [bs, 3*h_size, 1]\n",
    "        w_times_x = w_times_x.squeeze(-1)  # [bs, 3*h_size]\n",
    "        \n",
    "        w_times_h_prev = torch.bmm(batch_w_hh, prev_h.unsqueeze(-1))  # [bs, 3*h_size, 1]\n",
    "        w_times_h_prev = w_times_h_prev.squeeze(-1)  # [bs, 3*h_size]\n",
    "        \n",
    "        r_t = torch.sigmoid(w_times_x[:, :h_size]+w_times_h_prev[:, :h_size]+b_ih[:h_size]+b_hh[:h_size])  # 重置门\n",
    "        z_t = torch.sigmoid(w_times_x[:, h_size:2*h_size]+w_times_h_prev[:, h_size:2*h_size]\n",
    "                            +b_ih[h_size:2*h_size]+b_hh[h_size:2*h_size])  # 更新门\n",
    "        n_t = torch.tanh(w_times_x[:, 2*h_size:3*h_size]+b_ih[2*h_size:3*h_size]\n",
    "                         +r_t*(w_times_h_prev[:, 2*h_size:3*h_size]+b_hh[2*h_size:3*h_size]))  # 候选状态\n",
    "        prev_h = (1-z_t)*n_t + z_t*prev_h  # 增量更新得到当前时刻最新隐含状态\n",
    "        output[:, t, :] = prev_h\n",
    "        \n",
    "    return output, prev_h\n",
    "\n",
    "# 测试函数正确性\n",
    "\n",
    "bs, T, i_size, h_size = 2, 3, 4, 5\n",
    "input = torch.randn(bs, T, i_size)  # 输入序列\n",
    "h0 = torch.randn(bs, h_size)\n",
    "\n",
    "gru_layer = nn.GRU(i_size, h_size, batch_first=True)\n",
    "output, h_final = gru_layer(input,h0.unsqueeze(0))\n",
    "print(output)\n",
    "for k, v in gru_layer.named_parameters():\n",
    "    print(k, v.shape)\n",
    "    \n",
    "# 调用自定义的 gru_forward 函数\n",
    "output_custom, h_final_custom = gru_forward(input, h0, gru_layer.weight_ih_l0,\n",
    "                                            gru_layer.weight_hh_l0,\n",
    "                                            gru_layer.bias_ih_l0,\n",
    "                                            gru_layer.bias_hh_l0)\n",
    "\n",
    "print(torch.allclose(output, output_custom))\n",
    "print(torch.allclose(h_final, h_final_custom))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
