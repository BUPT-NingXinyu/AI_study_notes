{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3339191-1963-4901-b005-d7926e69559a",
   "metadata": {},
   "source": [
    "# 逐行讲解Masked_AutoEncoder(MAE)的PyTorch代码\n",
    "\n",
    "来自b站up主deep_thoughts 合集【PyTorch源码教程与前沿人工智能算法复现讲解】\n",
    "\n",
    "P_43_逐行讲解Masked_AutoEncoder(MAE)的PyTorch代码：\n",
    "\n",
    "https://www.bilibili.com/video/BV1JS4y1N7XE/?spm_id_from=333.788&vd_source=18e91d849da09d846f771c89a366ed40\n",
    "\n",
    "***论文***\n",
    "\n",
    "Masked Autoencoders Are Scalable Vision Learners：\n",
    "\n",
    "https://arxiv.org/pdf/2111.06377.pdf\n",
    "\n",
    "***代码***\n",
    "\n",
    "MAE：\n",
    "\n",
    "https://github.com/facebookresearch/mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcac072-b701-46e1-966d-f0772dfd1c87",
   "metadata": {},
   "source": [
    "# MAE code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ad1192-d588-4d63-a1e7-899de32ad9d8",
   "metadata": {},
   "source": [
    "## data preprocess\n",
    "* image2tensor\n",
    "  * RGB 3 channels\n",
    "  * PIL.Image.open+convert(\"RGB\"), or torchvision, datas ets.ImageFolder\n",
    "  * shape:(C,H,W),dtype:uint8\n",
    "    * unsigned integer 8 bit\n",
    "    * #000000\n",
    "    * #FFFFFF\n",
    "* augment\n",
    "  * Crop/Resize/Flip\n",
    "* convert (将uint8转换为[0,1]之间的浮点数)\n",
    "  * torchvision.transforms.ToPLIImage\n",
    "  * torchvision.transforms.PILToTensor()\n",
    "  * [0,1]\n",
    "* normalize\n",
    "  * (image-mean)/std,global-level\n",
    "  * imagenet1k\n",
    "    * mean:[0.485,0.456,0.406]\n",
    "    * std:[0.229,0.224,0.225]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b70d5dd-2d21-4b8c-b76d-7b9ac70409d2",
   "metadata": {},
   "source": [
    "## model\n",
    "* encoder\n",
    "  * image2patch2embedding\n",
    "  * position embedding\n",
    "  * random masking(shuffle)\n",
    "  * class token\n",
    "  * Transformer Blocks(ViT-base/Vit-large/Vit-huge)\n",
    "* decoder\n",
    "  * projection_layer\n",
    "  * unshuffle\n",
    "  * position embedding\n",
    "  * Transformer Blocks(shallow)\n",
    "  * regression layer\n",
    "  * mse loss function(norm pixel)\n",
    "* forward functions\n",
    "  * forward encoder\n",
    "  * forward decoder\n",
    "  * forward loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc46e234-1b06-4079-ad5e-fc6d1d10d35f",
   "metadata": {},
   "source": [
    "## training\n",
    "* dataset\n",
    "* data_loader\n",
    "* model\n",
    "* optimizer\n",
    "* load_model\n",
    "  * model.state_dict()\n",
    "  * optimizer.state_dict()\n",
    "  * epoch\n",
    "* train_one_epoch\n",
    "* save_model\n",
    "  * model.state_dict()\n",
    "  * optimizer.state_dict()\n",
    "  * epoch/loss\n",
    "  * config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08990b7-2a7b-4d9d-9f96-6aebff55722f",
   "metadata": {},
   "source": [
    "## finetuning\n",
    "* strong augmentation\n",
    "* build encoder + BN + MLP classifier head\n",
    "* interpolate position embedding\n",
    "* load pre-trained model(strict=False)\n",
    "* update all parameters\n",
    "* AdamW optimizer\n",
    "* label smoothing cross-entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d08f714-ae62-41a2-a288-acd70e3803a6",
   "metadata": {},
   "source": [
    "## linear probing\n",
    "* weak augmentation\n",
    "* build encoder + BN(no affine) + MLP classifier head\n",
    "* interpolate position embedding\n",
    "* only update parameters of MLP classifier head\n",
    "* LARS optimizer\n",
    "* cross-entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb63556-9c07-49d7-89cc-4bc2ee3c5b40",
   "metadata": {},
   "source": [
    "## evaluation\n",
    "* with torch.no_grad()\n",
    "  * efficient\n",
    "* model.eval()\n",
    "  * accurate BN/dropout\n",
    "* top_k\n",
    "  * top_1\n",
    "  * top_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eded874-018b-4650-b941-760d80c5aec2",
   "metadata": {},
   "source": [
    "## 演示shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fd2e56e-b4a4-4adf-8888-477a3e2a86c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2304, 0.9777, 0.2777, 0.2373, 0.9126])\n",
      "tensor([0, 3, 2, 4, 1])\n",
      "tensor([0, 4, 2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5)\n",
    "print(x)\n",
    "idx_shuffle = torch.argsort(x)\n",
    "print(idx_shuffle)\n",
    "idx_restore = torch.argsort(idx_shuffle)\n",
    "print(idx_restore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fd04fe-3de5-4586-93bf-e06911849dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
