{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "045ea604-f8a8-49c3-80e4-55a06332c193",
   "metadata": {},
   "source": [
    "# PyTorch中进行卷积残差模块算子融合\n",
    "\n",
    "来自b站up主deep_thoughts 合集【PyTorch源码教程与前沿人工智能算法复现讲解】\n",
    "\n",
    "P_16_PyTorch中进行卷积残差模块算子融合：\n",
    "    \n",
    "https://www.bilibili.com/video/BV1sU4y1u7TM/?spm_id_from=333.788&vd_source=18e91d849da09d846f771c89a366ed40\n",
    "\n",
    "Torch.nn 官方文档：https://pytorch.org/docs/stable/nn.html\n",
    "\n",
    "***论文***\n",
    "\n",
    "R-Drop: Regularized Dropout for Neural Networks：\n",
    "\n",
    "https://arxiv.org/pdf/2106.14448.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6cb2c4-b573-48bb-bf15-036978ab6990",
   "metadata": {},
   "source": [
    "## R Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c107dbca-92ae-4e57-8586-df8105b030ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def train_r_dropout(rate, x, w1, b1, w2, b2):\n",
    "    x = torch.cat([x, x], 0)\n",
    "    layer1 = np.maximum(0, np.dot(w1, x) + b1)\n",
    "    mask1 = np.random.binomial(1, 1-rate, layer1.shape)\n",
    "    layer1 = layer1*mask1\n",
    "    \n",
    "    layer2 = np.maximum(0, np.dot(w2, layer1) + b2)\n",
    "    mask2 = np.random.binomial(1, 1-rate, layer2.shape)\n",
    "    layer2 = layer2*mask2\n",
    "    \n",
    "    logits = func(layer2)\n",
    "    logits1, logits2 = logits[:bs, :], logits[bs:, :]\n",
    "    nll1 = nll(logits1, label)\n",
    "    nll2 = nll(logits2, label)\n",
    "    kl_loss = kl(logits1, logits2)\n",
    "    loss = nll1 + nll2 + kl_loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62e399e-0717-451b-b8fa-8f437a763f92",
   "metadata": {},
   "source": [
    "## Torch.nn.Conv2d\n",
    "官方文档：https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e6fc583-86b7-4493-969a-f4e657f2d8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', Parameter containing:\n",
      "tensor([[[[-0.0102,  0.1698,  0.2327],\n",
      "          [ 0.0041, -0.0713, -0.0640],\n",
      "          [ 0.1578,  0.2283,  0.2095]],\n",
      "\n",
      "         [[-0.0545,  0.0185, -0.1818],\n",
      "          [ 0.0845, -0.1467, -0.1645],\n",
      "          [-0.1213, -0.2126,  0.0537]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1197,  0.2086, -0.0750],\n",
      "          [ 0.0555,  0.0258,  0.1428],\n",
      "          [ 0.0094,  0.1274, -0.1129]],\n",
      "\n",
      "         [[-0.2097, -0.0310,  0.1732],\n",
      "          [-0.0508, -0.0166,  0.1956],\n",
      "          [-0.0259, -0.2299,  0.2276]]]], requires_grad=True))\n",
      "('bias', Parameter containing:\n",
      "tensor([ 0.0490, -0.0998], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "conv_layer = torch.nn.Conv2d(2, 2, 3, padding=\"same\")\n",
    "\n",
    "for i in conv_layer.named_parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6830efe2-3ee6-4c1e-beec-0ca0d2ea7400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.0102,  0.1698,  0.2327],\n",
      "          [ 0.0041, -0.0713, -0.0640],\n",
      "          [ 0.1578,  0.2283,  0.2095]],\n",
      "\n",
      "         [[-0.0545,  0.0185, -0.1818],\n",
      "          [ 0.0845, -0.1467, -0.1645],\n",
      "          [-0.1213, -0.2126,  0.0537]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1197,  0.2086, -0.0750],\n",
      "          [ 0.0555,  0.0258,  0.1428],\n",
      "          [ 0.0094,  0.1274, -0.1129]],\n",
      "\n",
      "         [[-0.2097, -0.0310,  0.1732],\n",
      "          [-0.0508, -0.0166,  0.1956],\n",
      "          [-0.0259, -0.2299,  0.2276]]]], requires_grad=True)\n",
      "torch.Size([2, 2, 3, 3])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(conv_layer.weight)\n",
    "print(conv_layer.weight.size())\n",
    "print(conv_layer.bias.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6def69-f73e-4f83-a7a9-ddd4e1c65678",
   "metadata": {},
   "source": [
    "### point-wise convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f2760c-959d-4fe9-98ed-b2470a7b54e5",
   "metadata": {},
   "source": [
    "* 1 X 1 卷积\n",
    "* channel mix\n",
    "* 相当于 MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b5e40e-d213-4ba5-ae2b-003efa8ddfc0",
   "metadata": {},
   "source": [
    "### depth-wise convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7345e1-2a5f-450b-9ba5-acc9cf2622c8",
   "metadata": {},
   "source": [
    "* groups 设置大于1的数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dc4b056-e8ab-4c24-9de9-cea7c3c89cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 3, 3])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "conv_layer = torch.nn.Conv2d(2, 4, 3, padding=\"same\", groups=2)\n",
    "print(conv_layer.weight.size())\n",
    "print(conv_layer.bias.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd205e4e-0b93-4cea-8005-3f71654a8de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 3, 3]) torch.Size([2])\n",
      "torch.Size([2, 1, 3, 3]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "conv_layer1 = torch.nn.Conv2d(1, 2, 3, padding=\"same\")\n",
    "conv_layer2 = torch.nn.Conv2d(1, 2, 3, padding=\"same\")\n",
    "print(conv_layer1.weight.size(), conv_layer1.bias.size())\n",
    "print(conv_layer2.weight.size(), conv_layer2.bias.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64263103-7e64-4aac-bb49-05af3ab6e9d0",
   "metadata": {},
   "source": [
    "## 卷积残差模块算子融合\n",
    "\n",
    "res_block = 3 X 3 conv + 1 X 1 conv + input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a4280a-4c46-4d3a-9ed4-78ea87e413a4",
   "metadata": {},
   "source": [
    "![](./img/P16_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c75e3212-7d63-4a35-9503-2535a680f051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "in_channels = 2\n",
    "out_channels = 2\n",
    "kernel_size = 3\n",
    "w = 9\n",
    "h = 9\n",
    "\n",
    "x = torch.ones(1, in_channels, w, h)  # 输入图片\n",
    "\n",
    "# 方法1：原生写法\n",
    "\n",
    "conv_2d = nn.Conv2d(in_channels, out_channels, kernel_size, padding=\"same\")\n",
    "conv_2d_pointwise = nn.Conv2d(in_channels, out_channels, 1)\n",
    "result1 = conv_2d(x) + conv_2d_pointwise(x) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a115977-a6a7-41a4-b6ac-b36dde78ee7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# 方法2：算子融合\n",
    "# 把 point-wise 卷积和 x 本身都写成 3*3 的卷积\n",
    "# 最终把三个卷积写成一个卷积\n",
    "# 1) 改造\n",
    "\n",
    "pointwise_to_conv_weight = F.pad(conv_2d_pointwise.weight, [1,1,1,1,0,0,0,0])  # 2*2*1*1->2*2*3*3\n",
    "conv_2d_for_pointwise = nn.Conv2d(in_channels, out_channels, kernel_size, padding=\"same\")\n",
    "conv_2d_for_pointwise.weight = nn.Parameter(pointwise_to_conv_weight)\n",
    "conv_2d_for_pointwise.bias = conv_2d_pointwise.bias\n",
    "\n",
    "# 2*2*3*3\n",
    "zeros = torch.unsqueeze(torch.zeros(kernel_size, kernel_size), 0)\n",
    "stars = torch.unsqueeze(F.pad(torch.ones(1, 1), [1,1,1,1]), 0)\n",
    "stars_zeros = torch.unsqueeze(torch.cat([stars, zeros], 0), 0)  # 第一个通道的卷积核\n",
    "zeros_stars = torch.unsqueeze(torch.cat([zeros, stars], 0), 0)  # 第二个通道的卷积核\n",
    "identity_to_conv_weight = torch.cat([stars_zeros, zeros_stars], 0)\n",
    "identity_to_conv_bias = torch.zeros([out_channels])\n",
    "conv_2d_for_identity = nn.Conv2d(in_channels, out_channels, kernel_size, padding=\"same\")\n",
    "conv_2d_for_identity.weight = nn.Parameter(identity_to_conv_weight)\n",
    "conv_2d_for_identity.bias = nn.Parameter(identity_to_conv_bias)\n",
    "\n",
    "result2 = conv_2d(x) + conv_2d_for_pointwise(x) + conv_2d_for_identity(x)\n",
    "\n",
    "print(torch.all(torch.isclose(result1, result2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4127be99-4b3c-4463-911f-10230d127933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# 2) 融合\n",
    "\n",
    "conv_2d_for_fusion = nn.Conv2d(in_channels, out_channels, kernel_size, padding=\"same\")\n",
    "conv_2d_for_fusion.weight = nn.Parameter(conv_2d.weight.data + conv_2d_for_pointwise.weight.data + conv_2d_for_identity.weight.data)\n",
    "conv_2d_for_fusion.bias = nn.Parameter(conv_2d.bias.data + conv_2d_for_pointwise.bias.data + conv_2d_for_identity.bias.data)\n",
    "result3 = conv_2d_for_fusion(x)\n",
    "\n",
    "print(torch.all(torch.isclose(result2, result3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e3c7cd-7d98-4c62-bed7-1b083f12f74e",
   "metadata": {},
   "source": [
    "## 时间比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18e4fd0c-47ea-42f0-95d2-362c81b659f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "原生写法耗时： 0.08690285682678223\n",
      "算子融合写法耗时： 0.06800007820129395\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 原生写法\n",
    "\n",
    "t1 = time.time()\n",
    "for i in range(1000):\n",
    "    result1 = conv_2d(x) + conv_2d_pointwise(x) + x\n",
    "t2 = time.time()\n",
    "\n",
    "# 融合写法\n",
    "for i in range(1000):\n",
    "    result3 = conv_2d_for_fusion(x)\n",
    "t3 = time.time()\n",
    "\n",
    "print(torch.all(torch.isclose(result1, result3)))\n",
    "print(\"原生写法耗时：\", t2-t1)\n",
    "print(\"算子融合写法耗时：\", t3-t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad85f909-94bc-4748-99f3-d4f689f6ef29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
